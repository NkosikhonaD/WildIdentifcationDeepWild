{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ProxyNCA_wits_zebra_ac_iter_rec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NkosikhonaD/WildIdentifcationDeepWild/blob/main/ProxyNCA_wits_zebra_ac_iter_rec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPh2hCP5eg7y",
        "outputId": "203d7e95-c925-4c7f-d3d6-c8ecbd48b5b0"
      },
      "source": [
        "!pip install pytorch-metric-learning\n",
        "!pip install faiss-gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-metric-learning in /usr/local/lib/python3.7/dist-packages (0.9.98)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (0.9.1+cu101)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-metric-learning) (4.41.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->pytorch-metric-learning) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.7.4.3)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pytorch-metric-learning) (1.0.1)\n",
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vLz2TiFem1V"
      },
      "source": [
        "from pytorch_metric_learning import losses, miners, reducers, distances, testers\n",
        "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DodJjz5WRrx_"
      },
      "source": [
        "\n",
        "#------------------------------imports EmbeddingNet------------------#\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.optim import Adam\n",
        "import torchvision\n",
        "\n",
        "import numpy as np\n",
        "from numpy import mean\n",
        "import torchvision.transforms as transforms\n",
        "#------------------------------imports Sampler-----------------------#\n",
        "from torch.utils.data.sampler import Sampler\n",
        "from collections import defaultdict\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#------------------------------imports Dataset-----------------------#\n",
        "from PIL import Image\n",
        "import PIL.ImageOps\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzyQOcofS2d6",
        "outputId": "2b775d8f-1010-4610-963c-69811fa50276"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKbWVD-gUWsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c0a431-bae5-4ac8-e1be-2d98a994bd70"
      },
      "source": [
        "animal_root = \"/content/drive/MyDrive/Zebra_img/\"\n",
        "root_train = animal_root+\"train\"\n",
        "root_test = animal_root+\"val\"\n",
        "!ls \"/content/drive/MyDrive/Zebra_img/\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name_rename.csv  train\tval\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNG6Epbm1RFM"
      },
      "source": [
        "def set_parameter_requires_grad(model,feature_extrating):\n",
        "  if feature_extrating:\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOSDfy8dyGNX"
      },
      "source": [
        "def initialize_model(model_name,num_classes,feature_extrating,use_pretrained= True):\n",
        "  model_ft=None\n",
        "  if model_name==\"resnet18\":\n",
        "    model_ft= models.resnet18(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft,feature_extrating)\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "\n",
        "  if model_name==\"resnet34\":\n",
        "    model_ft= models.resnet34(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft,feature_extrating)\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "\n",
        "  if model_name==\"resnet50\":\n",
        "    model_ft= models.resnet50(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft,feature_extrating)\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "  \n",
        "  if model_name==\"resnet101\":\n",
        "    model_ft= models.resnet101(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft,feature_extrating)\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "    \n",
        "  if model_name==\"resnet152\":\n",
        "    model_ft= models.resnet152(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft,feature_extrating)\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "  if model_name ==\"VGG19\":\n",
        "    model_ft= models.vgg19(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft,feature_extrating)\n",
        "    num_ftrs= model_ft.classifier[6].in_features\n",
        "    model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "  if model_name ==\"VGG11\":\n",
        "    model_ft= models.vgg11(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft,feature_extrating)\n",
        "    num_ftrs= model_ft.classifier[6].in_features\n",
        "    model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "  \n",
        "  if model_name ==\"densenet121\":\n",
        "    model_ft= models.densenet121(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft,feature_extrating)\n",
        "    num_ftrs= model_ft.classifier.in_features\n",
        "    model_ft.classifier = nn.Linear(num_ftrs,num_classes)\n",
        "  if model_name ==\"densenet201\":\n",
        "    model_ft= models.densenet201(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft,feature_extrating)\n",
        "    num_ftrs= model_ft.classifier.in_features\n",
        "    model_ft.classifier = nn.Linear(num_ftrs,num_classes)\n",
        "  return model_ft\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5pH9uxOZ1Zf"
      },
      "source": [
        "class EmbeddingNet(nn.Module):\n",
        "  def __init__(self,model_name,num_classes,feature_extrating,use_pretrained):\n",
        "    super(EmbeddingNet,self).__init__()\n",
        "    self.backbone = model_name\n",
        "    if model_name is None:\n",
        "      #initialize_model(model_name,num_classes = 128,feature_extract,use_pretrained= True)\n",
        "      self.backbone = models.resnet18(num_classes=128)\n",
        "    else:\n",
        "        self.backbone =initialize_model(model_name,num_classes,feature_extrating,use_pretrained)\n",
        "    #self.backbone = backbone\n",
        "  def forward(self,x):\n",
        "    x=self.backbone(x)\n",
        "    x= nn.functional.normalize(x,dim=1)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVinsN95iqLx"
      },
      "source": [
        "def show_plot_two(x_axis_array1,y_axis_array1,y_axis_array2,graph_1_lab=\"gr1\",graph_2_lab=\"gr2\",title=\"set title\",x_label=\"epoch\",y_label=\"loss\"):\n",
        "  \n",
        "  if len(x_axis_array1)!= len(y_axis_array1):\n",
        "    ly1 =min(len(x_axis_array1),len(y_axis_array1))\n",
        "    ly2 =min(len(x_axis_array1),len(y_axis_array2))\n",
        "    \n",
        "    plt.plot(x_axis_array1[:ly1],y_axis_array1[:ly1],label=graph_1_lab)\n",
        "    plt.plot(x_axis_array1[:ly2],y_axis_array2[:ly2],label=graph_2_lab)\n",
        "  else:\n",
        "    plt.plot(x_axis_array1,y_axis_array1,label=graph_1_lab)\n",
        "    plt.plot(x_axis_array1,y_axis_array2,label=graph_2_lab)\n",
        "\n",
        "  plt.xlabel(x_label)\n",
        "  plt.ylabel(y_label)   \n",
        "  plt.title(title)\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ANJynxPSo2u"
      },
      "source": [
        "def show_plot(x_axis_array,y_axis_array, title=\"set title\",x_label=\"set_xlabes\",y_label=\"set_ylabels\"):\n",
        "  plt.plot(x_axis_array,y_axis_array)\n",
        "  plt.xlabel(x_label)\n",
        "  plt.ylabel(y_label)\n",
        "  plt.title(title)\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR6xu2PnKaaW"
      },
      "source": [
        "class OnlineTripletDataset(Dataset):\n",
        "  def __init__(self,imageFolderDataset,transform=None,should_invert=True):\n",
        "    self.imageFolderDataset = imageFolderDataset\n",
        "    self.should_invert= should_invert\n",
        "    self.transform = transform\n",
        "    #self.targets = [img[1] for img in self.imageFolderDataset.imgs]\n",
        "    self.targets = [name[1] for name in self.imageFolderDataset.imgs]\n",
        "    self.targets = list(set(self.targets))\n",
        "  def __getitem__(self,index):\n",
        "    img0_tuple = random.choice(self.imageFolderDataset.imgs)\n",
        "    img0 = Image.open(img0_tuple[0])\n",
        "    target = img0_tuple[1]\n",
        "\n",
        "    if self.should_invert:\n",
        "      img0=PIL.ImageOps.invert(img0)\n",
        "    if self.transform is not None:\n",
        "      img0=self.transform(img0)\n",
        "    return img0, torch.from_numpy(np.array([int(target)],dtype=np.float32))\n",
        "  def __len__(self):\n",
        "    return (len(self.imageFolderDataset.imgs))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv75g9oX3BIH"
      },
      "source": [
        "accuracy_list = []\n",
        "embeds = []\n",
        "labels= []\n",
        "train_loss = []\n",
        "test_loss = []\n",
        "epoch_iterator = []\n",
        "test_iterator = []\n",
        "dists = None\n",
        "targets = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2aqPmp_iPLy"
      },
      "source": [
        "def train_epoch(model,optimizer,loss_optimizer,criterion,data_loader,device,epoch,print_freq):\n",
        "  model.train()\n",
        "  running_loss = 0;\n",
        "  running_frac_pos_triplets= 0\n",
        "  epoch_iterator.append(epoch)\n",
        "  for i, data in enumerate(data_loader):\n",
        "    optimizer.zero_grad()\n",
        "    samples, targets = data[0].to(device),data[1].to(device)\n",
        "    embeddings = model(samples)\n",
        "    #loss,frac_pos_triplets = criterion(embeddings,targets)\n",
        "    targets = torch.flatten(targets)\n",
        "    loss = criterion(embeddings,targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss_optimizer.step()\n",
        "    running_loss +=loss.item()\n",
        "\n",
        "    #running_frac_pos_triplets+=float(frac_pos_triplets)\n",
        "\n",
        "    if i%print_freq ==print_freq-1:\n",
        "      i+=1\n",
        "      avg_loss = running_loss/print_freq\n",
        "      train_loss.append(avg_loss)\n",
        "      \n",
        "      #avg_trip =100.0*running_frac_pos_triplets/print_freq\n",
        "      #print('[{:d}, {:d}] | loss: {:.4f} | % avg hard triplets: {:.2f}%'.format(epoch, i, avg_loss, avg_trip))\n",
        "      print('[{:d}, {:d}] | loss: {:.4f}'.format(epoch, i, avg_loss))\n",
        "      running_loss = 0\n",
        "      running_frac_pos_triplets = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWwUJ9IkcEmq"
      },
      "source": [
        "def imshow(img,text=None,should_save= False):\n",
        "  npimg = img.cpu().numpy()\n",
        "  plt.axis(\"off\")\n",
        "  if text:\n",
        "    plt.text(75,8,text,style='italic',fontweight='bold',bbox={'facecolor':'white','alpha':0.8,'pad':10})\n",
        "  plt.imshow(np.transpose(npimg,(1,2,0)))\n",
        "  plt.show()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OO0cD7Of64A"
      },
      "source": [
        "def save(model,epoch,save_dir,file_name):\n",
        "  file_name = 'epoch_'+str(epoch)+'_'+file_name\n",
        "  save_path =os.path.join(save_dir,file_name)\n",
        "  torch.save(model.state_dict(),save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scWKE9nPGUTP",
        "outputId": "57904648-b7f6-46db-c860-4a8675300149"
      },
      "source": [
        "\n",
        "folder_dataset_train = dset.ImageFolder(root=root_train)\n",
        "#folder_dataset_test = dset.ImageFolder(root=\"/content/drive/My Drive/ColabNotebooks/DataProcessed/Nyla_Data/val\")\n",
        "\n",
        "#train_dataset = OnlineTripletDataset(imageFolderDataset=folder_dataset_train,transform=transforms.Compose([transforms.Resize(128),transforms.CenterCrop(124),transforms.ToTensor()]),should_invert=False)\n",
        "#test_dataset= OnlineTripletDataset(imageFolderDataset=folder_dataset_test,transform=transforms.Compose([transforms.Resize(28),transforms.CenterCrop(124),transforms.ToTensor(),transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])]),should_invert=False)\n",
        "train_dataset = OnlineTripletDataset(imageFolderDataset=folder_dataset_train,transform=transforms.Compose([transforms.Resize(128),transforms.CenterCrop(124),transforms.ToTensor()]),should_invert=False) \n",
        "#train_dataset._len_()\n",
        "targets = train_dataset.targets\n",
        "print(\"Total targets = \"+str(len(targets)))\n",
        "train_dataloader = DataLoader(train_dataset,num_workers =2,batch_size=6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total targets = 45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GqhQ7-2_iPu",
        "outputId": "41a8bfd2-581c-4d6f-ebe8-f0491fdf7fe8"
      },
      "source": [
        "folder_dataset_test = dset.ImageFolder(root=root_test)\n",
        "#folder_dataset_test = dset.ImageFolder(root=\"/content/drive/My Drive/ColabNotebooks/DataProcessed/Lion_Data/val\")\n",
        "\n",
        "#train_dataset = OnlineTripletDataset(imageFolderDataset=folder_dataset_train,transform=transforms.Compose([transforms.Resize(28),transforms.CenterCrop(24),transforms.ToTensor()]),should_invert=False)\n",
        "test_dataset= OnlineTripletDataset(imageFolderDataset=folder_dataset_test,transform=transforms.Compose([transforms.Resize(128),transforms.CenterCrop(124),transforms.ToTensor(),transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])]),should_invert=False)\n",
        "#test_dataset._len_()\n",
        "test_dataloader = DataLoader(test_dataset,num_workers=2,batch_size=6,shuffle=False) \n",
        "\n",
        "targets_test = test_dataset.targets\n",
        "print(\"targets test \",str(len(targets_test)))\n",
        "device = torch.device('cuda')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "targets test  41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "befrcc4eW_CL",
        "outputId": "18b5d218-d7d9-4def-b2eb-fa9a227aa390"
      },
      "source": [
        "backbone_name = [\"resnet18\",\"resnet34\",\"resnet50\",\"resnet101\",\"resnet152\",\"VGG19\",\"VGG11\",\"densenet121\",\"densenet201\"]\n",
        "feature_extract =True\n",
        "extract_or_fine_tune=[\"tune\",\"extr\"]\n",
        "dataset_used=\"Zebra_img\"\n",
        "backbone = backbone_name[8]\n",
        "mode_train =extract_or_fine_tune[feature_extract]\n",
        "\n",
        "dim = [32,64,128,256,512]\n",
        "dim_embedd=dim[1]\n",
        "saved_model=backbone+mode_train+str(dim_embedd)+dataset_used+\".pt\"\n",
        "print(saved_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "densenet201extr64Zebra_img.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvFTBuOZg51g"
      },
      "source": [
        "def get_all_embeddings(dataset,model):\n",
        "  tester = testers.BaseTester()\n",
        "  return tester.get_all_embeddings(dataset,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAgpiYKng6jg"
      },
      "source": [
        "def test(test1_samples,test2_samples,model,accuracy_calculator):\n",
        "  test1_embeddings,test1_labels = get_all_embeddings(test1_samples,model)\n",
        "  test2_embeddings,test2_labels = get_all_embeddings(test2_samples,model)\n",
        "  accuracies = accuracy_calculator.get_accuracy(test1_embeddings,test2_embeddings,np.squeeze(test1_labels),np.squeeze(test2_labels),False)\n",
        "   \n",
        "  print(\"MAP \",accuracies[\"mean_average_precision\"],\"MAP@R \",accuracies[\"mean_average_precision_at_r\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmysnzus_ej7"
      },
      "source": [
        "\n",
        "def test_epoch(model,criterion,loss_optimizer,data_loader,device,epoch,print_freq):\n",
        "  model.eval()\n",
        "  model.to(device)\n",
        "  running_loss = 0;\n",
        "  running_frac_pos_triplets= 0\n",
        "  model_string = animal_root+\"epoch_\"+str(epoch)+\"_\"+saved_model\n",
        "  model.load_state_dict(torch.load(model_string))\n",
        "  test_iterator.append(epoch)\n",
        "  for i, data in enumerate(data_loader):\n",
        "    samples, targets = data[0].to(device),data[1].to(device)\n",
        "    targets = torch.flatten(targets)\n",
        "    embeddings = model(samples) \n",
        "    loss = criterion(embeddings,targets)\n",
        "    loss_optimizer.step()\n",
        "    running_loss +=loss.item()\n",
        "    if i%print_freq ==print_freq-1:\n",
        "      i+=1\n",
        "      avg_loss = running_loss/print_freq\n",
        "      test_loss.append(avg_loss)\n",
        "      print('[{:d}, {:d}] | loss: {:.4f}'.format(epoch, i, avg_loss))\n",
        "      running_loss = 0\n",
        "      running_frac_pos_triplets = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGCKEVVg7RSk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd2f00b7-0f6e-45c2-c2e7-53f790c93043"
      },
      "source": [
        "test_loss = []\n",
        "test_iterator = []\n",
        "device = torch.device('cuda:0')\n",
        "#def __init__(self,model_name,num_classes,feature_extrating,use_pretrained):\n",
        "feature_extract = True \n",
        "#using model as a feature extractor... not fineturning all layers\n",
        "model = EmbeddingNet(backbone,dim_embedd,feature_extract,True)\n",
        "model.to(device)\n",
        "params_to_update = model.parameters()\n",
        "if feature_extract:\n",
        "  params_to_update= []\n",
        "  for name, param in model.named_parameters():\n",
        "    if param.requires_grad==True:\n",
        "      params_to_update.append(param)\n",
        "      print(\"\\t\",name)\n",
        "else:\n",
        "  for name,param in model.named_parameters():\n",
        "    if param.requires_grad==True:\n",
        "      print(\"\\t\",name)\n",
        "\n",
        "print_freq = 150\n",
        "criterion = losses.ProxyNCALoss(45,dim_embedd,softmax_scale=1) # hyper parameter margin can be changed\n",
        "optimizer = Adam(params_to_update,lr=0.0001)\n",
        "loss_optimizer = Adam(criterion.parameters(),lr=0.0001)\n",
        "for epoch in range(1,31):\n",
        "  print('Training...',backbone,mode_train)\n",
        "  train_epoch(model,optimizer,loss_optimizer,criterion,train_dataloader,device,epoch,print_freq)\n",
        "  save(model,epoch,animal_root,saved_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t backbone.classifier.weight\n",
            "\t backbone.classifier.bias\n",
            "Training... densenet201 extr\n",
            "[1, 150] | loss: 3.6656\n",
            "Training... densenet201 extr\n",
            "[2, 150] | loss: 3.3504\n",
            "Training... densenet201 extr\n",
            "[3, 150] | loss: 3.1356\n",
            "Training... densenet201 extr\n",
            "[4, 150] | loss: 3.0119\n",
            "Training... densenet201 extr\n",
            "[5, 150] | loss: 2.9237\n",
            "Training... densenet201 extr\n",
            "[6, 150] | loss: 2.8487\n",
            "Training... densenet201 extr\n",
            "[7, 150] | loss: 2.7884\n",
            "Training... densenet201 extr\n",
            "[8, 150] | loss: 2.7647\n",
            "Training... densenet201 extr\n",
            "[9, 150] | loss: 2.7222\n",
            "Training... densenet201 extr\n",
            "[10, 150] | loss: 2.7102\n",
            "Training... densenet201 extr\n",
            "[11, 150] | loss: 2.6590\n",
            "Training... densenet201 extr\n",
            "[12, 150] | loss: 2.6327\n",
            "Training... densenet201 extr\n",
            "[13, 150] | loss: 2.6222\n",
            "Training... densenet201 extr\n",
            "[14, 150] | loss: 2.6054\n",
            "Training... densenet201 extr\n",
            "[15, 150] | loss: 2.5772\n",
            "Training... densenet201 extr\n",
            "[16, 150] | loss: 2.5757\n",
            "Training... densenet201 extr\n",
            "[17, 150] | loss: 2.5589\n",
            "Training... densenet201 extr\n",
            "[18, 150] | loss: 2.5447\n",
            "Training... densenet201 extr\n",
            "[19, 150] | loss: 2.5334\n",
            "Training... densenet201 extr\n",
            "[20, 150] | loss: 2.5169\n",
            "Training... densenet201 extr\n",
            "[21, 150] | loss: 2.5121\n",
            "Training... densenet201 extr\n",
            "[22, 150] | loss: 2.5241\n",
            "Training... densenet201 extr\n",
            "[23, 150] | loss: 2.5147\n",
            "Training... densenet201 extr\n",
            "[24, 150] | loss: 2.4664\n",
            "Training... densenet201 extr\n",
            "[25, 150] | loss: 2.4941\n",
            "Training... densenet201 extr\n",
            "[26, 150] | loss: 2.4791\n",
            "Training... densenet201 extr\n",
            "[27, 150] | loss: 2.4769\n",
            "Training... densenet201 extr\n",
            "[28, 150] | loss: 2.4671\n",
            "Training... densenet201 extr\n",
            "[29, 150] | loss: 2.4730\n",
            "Training... densenet201 extr\n",
            "[30, 150] | loss: 2.4781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq--BGehX3mS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9fb93ab0-d4ea-406e-ad2a-3a94eb1e1e49"
      },
      "source": [
        "feature_extract = False \n",
        "#using model as a feature extractor... not fineturning all layers\n",
        "model = EmbeddingNet(backbone,dim_embedd,feature_extract,True)\n",
        "#model = EmbeddingNet(\"VGG19\",)\n",
        "criterion = losses.ProxyNCALoss(41,dim_embedd,softmax_scale=1)\n",
        "loss_optimizer = Adam(criterion.parameters(),lr=0.01) \n",
        "print_freq = 40\n",
        "for epoch in range(1,31):\n",
        "  print('Testing ...',backbone,mode_train)\n",
        "  test_epoch(model,criterion,loss_optimizer,test_dataloader,device,epoch,print_freq)    \n",
        "show_plot_two(test_iterator,train_loss,test_loss,\"train\",\"validate\",\"Triplet loss\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing ... densenet201 extr\n",
            "[1, 40] | loss: 3.7157\n",
            "Testing ... densenet201 extr\n",
            "[2, 40] | loss: 3.7180\n",
            "Testing ... densenet201 extr\n",
            "[3, 40] | loss: 3.7339\n",
            "Testing ... densenet201 extr\n",
            "[4, 40] | loss: 3.7186\n",
            "Testing ... densenet201 extr\n",
            "[5, 40] | loss: 3.7207\n",
            "Testing ... densenet201 extr\n",
            "[6, 40] | loss: 3.7738\n",
            "Testing ... densenet201 extr\n",
            "[7, 40] | loss: 3.7372\n",
            "Testing ... densenet201 extr\n",
            "[8, 40] | loss: 3.7371\n",
            "Testing ... densenet201 extr\n",
            "[9, 40] | loss: 3.7447\n",
            "Testing ... densenet201 extr\n",
            "[10, 40] | loss: 3.7329\n",
            "Testing ... densenet201 extr\n",
            "[11, 40] | loss: 3.7403\n",
            "Testing ... densenet201 extr\n",
            "[12, 40] | loss: 3.7926\n",
            "Testing ... densenet201 extr\n",
            "[13, 40] | loss: 3.7314\n",
            "Testing ... densenet201 extr\n",
            "[14, 40] | loss: 3.7503\n",
            "Testing ... densenet201 extr\n",
            "[15, 40] | loss: 3.7509\n",
            "Testing ... densenet201 extr\n",
            "[16, 40] | loss: 3.7879\n",
            "Testing ... densenet201 extr\n",
            "[17, 40] | loss: 3.7587\n",
            "Testing ... densenet201 extr\n",
            "[18, 40] | loss: 3.7501\n",
            "Testing ... densenet201 extr\n",
            "[19, 40] | loss: 3.7620\n",
            "Testing ... densenet201 extr\n",
            "[20, 40] | loss: 3.7428\n",
            "Testing ... densenet201 extr\n",
            "[21, 40] | loss: 3.7742\n",
            "Testing ... densenet201 extr\n",
            "[22, 40] | loss: 3.7676\n",
            "Testing ... densenet201 extr\n",
            "[23, 40] | loss: 3.7902\n",
            "Testing ... densenet201 extr\n",
            "[24, 40] | loss: 3.7757\n",
            "Testing ... densenet201 extr\n",
            "[25, 40] | loss: 3.7951\n",
            "Testing ... densenet201 extr\n",
            "[26, 40] | loss: 3.7918\n",
            "Testing ... densenet201 extr\n",
            "[27, 40] | loss: 3.7858\n",
            "Testing ... densenet201 extr\n",
            "[28, 40] | loss: 3.7530\n",
            "Testing ... densenet201 extr\n",
            "[29, 40] | loss: 3.7770\n",
            "Testing ... densenet201 extr\n",
            "[30, 40] | loss: 3.7830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giX64r8uh_Dq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5643aea5-6329-4d04-87c1-4f2c2c49a130"
      },
      "source": [
        "print(\"Evaluating model\",backbone,mode_train)\n",
        "test_dataset1= OnlineTripletDataset(imageFolderDataset=folder_dataset_test,transform=transforms.Compose([transforms.Resize(128),transforms.CenterCrop(124),transforms.ToTensor(),transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])]),should_invert=False)\n",
        "test_dataset2= OnlineTripletDataset(imageFolderDataset=folder_dataset_test,transform=transforms.Compose([transforms.Resize(128),transforms.CenterCrop(124),transforms.ToTensor(),transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])]),should_invert=False)\n",
        "\n",
        "accuracy_calculator = AccuracyCalculator(include = (\"mean_average_precision\",\"mean_average_precision_at_r\",),k=None)\n",
        "accuracy_calculator2 = AccuracyCalculator(include = (\"mean_average_precision\",\"mean_average_precision_at_r\",),k=1)\n",
        "model = EmbeddingNet(backbone,dim_embedd,False,True)\n",
        "model.to(device)\n",
        "model_string = animal_root+\"epoch_\"+str(30)+\"_\"+saved_model\n",
        "model.load_state_dict(torch.load(model_string))\n",
        "test(test_dataset1,test_dataset2,model,accuracy_calculator)\n",
        "print(\" ---------------   Evaluate model at k =1 --------------------------------------\")\n",
        "test(test_dataset1,test_dataset2,model,accuracy_calculator2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating model densenet201 extr\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
            "100%|██████████| 10/10 [00:08<00:00,  1.12it/s]\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MAP  0.37617605089030115 MAP@R  0.27975702325905527\n",
            " ---------------   Evaluate model at k =1 --------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:09<00:00,  1.09it/s]\n",
            "100%|██████████| 10/10 [00:08<00:00,  1.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MAP  0.7876712328767123 MAP@R  0.7876712328767123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L4q6r--SljD"
      },
      "source": [
        "mydir =animal_root\n",
        "for f in os.listdir(mydir):\n",
        "    if not f.endswith(\".pt\"):\n",
        "        continue\n",
        "    os.remove(os.path.join(mydir, f))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}